{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"provenance":[],"toc_visible":true},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["- Gensim models were done using gensim with lemmatization and stopwords as that was found to be the best method\n","- This file also trains a model using Gensim FastText \n","- This file also contains the training for the Hugging Face BERT byte pair encoding model"],"metadata":{"id":"d7HPG8dNRSnp"}},{"cell_type":"markdown","metadata":{"id":"Z-acCjLbFeJt"},"source":["# Training Gensim model on neuroscience papers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbvsKVqd8vG0","executionInfo":{"status":"ok","timestamp":1675644451285,"user_tz":300,"elapsed":29836,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"outputId":"32d5d79a-1186-4a64-9ef2-66a66626e34c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"j_HTqeOlLwkp","executionInfo":{"status":"ok","timestamp":1675644459018,"user_tz":300,"elapsed":7735,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"745523c0-30d6-4565-daaa-fba8657c65a5"},"source":["!pip install python-docx"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python-docx\n","  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from python-docx) (4.9.2)\n","Building wheels for collected packages: python-docx\n","  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184505 sha256=7f2b58938271ed2271877f3f88a467f2b3dcee3583a735665d49b590ee3ac278\n","  Stored in directory: /root/.cache/pip/wheels/32/b8/b2/c4c2b95765e615fe139b0b17b5ea7c0e1b6519b0a9ec8fb34d\n","Successfully built python-docx\n","Installing collected packages: python-docx\n","Successfully installed python-docx-0.8.11\n"]}]},{"cell_type":"code","metadata":{"id":"70HN_RS6T8OD","executionInfo":{"status":"ok","timestamp":1675644463791,"user_tz":300,"elapsed":4778,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"88394e60-ba09-499e-f3f6-4df754415ee7"},"source":["!pip install glove_python-binary"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting glove_python-binary\n","  Downloading glove_python_binary-0.2.0-cp38-cp38-manylinux1_x86_64.whl (974 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.9/974.9 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from glove_python-binary) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from glove_python-binary) (1.21.6)\n","Installing collected packages: glove_python-binary\n","Successfully installed glove_python-binary-0.2.0\n"]}]},{"cell_type":"code","metadata":{"id":"CYDKvAMYLy4s","executionInfo":{"status":"ok","timestamp":1675644465165,"user_tz":300,"elapsed":1376,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"466f30b5-1f6c-4122-c026-2ac756b28149"},"source":["from docx import Document\n","import nltk\n","nltk.download('punkt')\n","import re\n","from nltk import sent_tokenize\n","import pandas as pd\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","import pickle\n","import numpy as np\n","import glob"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"BDPlGB-qwa6Q","executionInfo":{"status":"ok","timestamp":1675644465165,"user_tz":300,"elapsed":4,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5451d52-edef-4428-ad5b-82ddc5caafe2"},"source":["from nltk.stem import WordNetLemmatizer\n","import nltk \n","nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"qJqALNlWL07y","executionInfo":{"status":"ok","timestamp":1675644465843,"user_tz":300,"elapsed":680,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"696ad945-e652-4a76-e577-f266c3ad2f08"},"source":["!git clone 'https://github.com/igorbrigadir/stopwords.git'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'stopwords'...\n","remote: Enumerating objects: 149, done.\u001b[K\n","remote: Total 149 (delta 0), reused 0 (delta 0), pack-reused 149\u001b[K\n","Receiving objects: 100% (149/149), 85.27 KiB | 14.21 MiB/s, done.\n","Resolving deltas: 100% (52/52), done.\n"]}]},{"cell_type":"code","metadata":{"id":"JhyPjMvkL3fb"},"source":["alir3z4_data = '/content/stopwords/en/alir3z4.txt'\n","\n","more_stops = pd.read_csv('/content/stopwords/en/alir3z4.txt')\n","new_stops = list(more_stops[\"'ll\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2QIGTVVjMGw3"},"source":["DOMAIN_STOPS = {'pubmed', 'et', 'al', 'page'}\n","STOPWORDS =  set(stopwords.words('english') + stopwords.words('german') +  stopwords.words('dutch') + stopwords.words('french') +  stopwords.words('spanish')  + new_stops) | DOMAIN_STOPS\n","STOPWORDS = set(STOPWORDS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8pcXJs1MJXa","executionInfo":{"status":"ok","timestamp":1675644465844,"user_tz":300,"elapsed":8,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4bc4810d-a718-4521-e19e-ac3a80622abb"},"source":["len(STOPWORDS)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2011"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"-84pfgeZvXIK","executionInfo":{"status":"ok","timestamp":1675644465845,"user_tz":300,"elapsed":7,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"27c012fa-f7ef-4187-cbb7-6b4f7e5261a9"},"source":["'a' in STOPWORDS"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"XAIUEHTcyP4K"},"source":["ROOT = \"/content/drive/MyDrive/regen_x\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CohG2_FkMKh5"},"source":["def get_docx(file_path):\n","    doc = []\n","    for para in Document(file_path).paragraphs:\n","        if para.text == \"\":\n","            continue\n","        doc += (sent_tokenize(para.text.lower())) # we lower text here\n","    return doc\n","\n","\n","def get_start_stop():\n","    domain_stops = {'pubmed', 'et', 'al', 'page'}\n","    with open('/content/stopwords/en/alir3z4.txt', 'r') as fn:\n","        new_stops = [line.strip() for line in fn.readlines()]\n","    STOPWORDS =  set(stopwords.words('english') + stopwords.words('german') +  stopwords.words('dutch') + stopwords.words('french') +  stopwords.words('spanish')  + new_stops) | domain_stops\n","\n","    fn = glob.glob(ROOT + '/data/start-words/*')\n","    ALL_STARTS = [pickle.load(open(f , 'rb')) for f in fn]\n","    STARTWORDS = {}\n","    for f in ALL_STARTS:\n","      STARTWORDS.update(f)\n","    STARTWORDS = set(STARTWORDS.keys())\n","\n","    assert(type(STOPWORDS)==set and type(STARTWORDS)==set)\n","    return (STARTWORDS, STOPWORDS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZoJbCIdJVwBq"},"source":["STARTWORDS, STOPWORDS = get_start_stop()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"82OoKfEym1uK"},"source":["# from gensim.models import Word2Vec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K0rsrAgqMRJm"},"source":["# Optimizing Training Function"]},{"cell_type":"markdown","metadata":{"id":"KFddKJvTSFMi"},"source":["You **don't** want to do incremental training for the reasons given in [this answer](https://stackoverflow.com/questions/42746007/incremental-word2vec-model-training-in-gensim)"]},{"cell_type":"markdown","metadata":{"id":"34kR_V0rafxd"},"source":["# Lemmatizing, Concatenating, and Training Gensim Model"]},{"cell_type":"code","source":["# Don't forget to mount drive"],"metadata":{"id":"n20RiGhYTSs3"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wm2DqshdhtV"},"source":["from natsort import natsorted\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDuMaDxdcrws"},"source":["ROOT = \"/content/drive/MyDrive/regen_x\"\n","NUM_BINS = 16"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79xopbjgug8O"},"source":["# for lemmatization \n","import spacy\n","# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\n","nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtM5zNcln_nJ"},"source":["def do_stemming(filtered):\n","\tstemmed = []\n","\tfor f in filtered:\n","\t\tstemmed.append(PorterStemmer().stem(f))\n","\t\t#stemmed.append(LancasterStemmer().stem(f))\n","\t\t#stemmed.append(SnowballStemmer('english').stem(f))\n","\treturn stemmed\n","\n","def do_lemmatizing(filtered):\n","  # convert list to string \n","  spacy_parsed_text = nlp(\" \".join(filtered)) \n","  # Get the lemma for each token in the parsed text \n","  \n","  # I wanted to keep pronouns so not taking lemma if it's a pronoun but if you want to remove pronouns use below commented line \n","  # return \" \".join([token.lemma_ for token in doc])\n","\n","  # return as list of words again \n","  return [token.lemma_ if token.lemma_ != '-PRON-' else token.lower_ for token in spacy_parsed_text]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2IO2O1znJZW"},"source":["# Uses lemmatization and stopwords \n","def get_proc_docs_total(all_papers_path, STARTWORDS, STOPWORDS, max_papers=None, verbose=True):\n","  file_paths = all_papers_path\n","\n","  print(\"Number of files: {}\".format(len(file_paths)))\n","  if len(file_paths) == 0:\n","    # raise Exception(\"Folder has no files - maybe drive was not mounted?\")\n","    pass \n","  ## -- Collecting Papers from Given Year -- ##\n","  proc_docs = [] \n","\n","  counter = 1\n","  length = len(file_paths)\n","  for f in file_paths:\n","    doc = get_docx(f)\n","    \n","    for sentence in doc:\n","      # don't think we need to remove stopwords and such if we're training embeddings \n","      # do lemmatization here as well \n","\n","      proc_sentence = [] \n","      proc_sentence = [word for word in re.findall(r'\\w+', sentence) if ((len(word) > 2) and (word not in STOPWORDS))]\n","\n","      proc_sentence = do_lemmatizing(proc_sentence) \n","      \n","      proc_docs.append(proc_sentence)  \n","\n","    if(verbose):\n","      print(\"\\t{}/{}\".format(counter, length))\n","    counter += 1\n","\n","    if max_papers != None:\n","      if counter == max_papers+1:\n","        break \n","\n","  return proc_docs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FHxMSeusneBl"},"source":["# MODEL_PATH = \"/content/drive/MyDrive/Colab Notebooks/NLP - Lab/WordEmbeddings/Models/Gensim_Lemmatized_All_Docs/\"\n","\n","# if not os.path.exists(MODEL_PATH):\n","#     print(\"New path created\")\n","#     os.makedirs(MODEL_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_papers_path = glob.glob(ROOT + '/data/ocr_paper_COMPREHENSIVE/*/*.docx')\n","all_papers_path[160:170]"],"metadata":{"id":"k_BSK8nAWTXn"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGLmFO4Bdcz9"},"source":["### Train and Save Models for all time periods ##\n","\n","# Have to make one giant list of all processed docs because unfortunately can't incrementally \n","# train as described above \n","counter = 0 \n","\n","all_proc_docs = [] \n","\n","# Process the docs (stopwords and lemmatization)\n","all_proc_docs = get_proc_docs_total(all_papers_path, STARTWORDS, STOPWORDS, max_papers=None, verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the embeddings! \n","print(\"Training word embeddings for all papers...\")\n","model = Word2Vec(sentences=all_proc_docs, min_count=1) \n","\n","# Sanity check \n","print(model.wv.most_similar(\"eye\", topn=10))\n","\n","# Store just the words + their trained embeddings.\n","word_vectors = model.wv\n","word_vectors.save(MODEL_PATH + \"{}.wordvectors\".format(\"All Papers\"))\n","\n","# Manually create space \n","# del all_proc_docs\n","# del word_vectors \n","# del model "],"metadata":{"id":"40kDAMjC0mrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uIPvngFbowMh"},"source":["# Exceution of above function took: 1h 5min\n","# Processing docs: 1h 3min\n","# Training embeddings: 2 min "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gensim FastText"],"metadata":{"id":"BiQLgttvb6rL"}},{"cell_type":"code","source":["from gensim.models import FastText"],"metadata":{"id":"uArfChB6b6Ix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_papers_path = glob.glob('/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/*/*.docx')\n","all_papers_path[160:170]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wliQ5n8zcP6B","executionInfo":{"status":"ok","timestamp":1675648922409,"user_tz":300,"elapsed":485,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"outputId":"ecd0510a-6d3c-4235-db3f-71d42618be68"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1915/1915_R. H. Jocelyn Swan.docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1915/1915_R. Ingebrigtsen.docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1915/1915_The British Medical Journal.docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1915/1915_T. N. Foulis.docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1915/1915_W. Harris.docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1916/1916_A. R. Robertson.docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1916/1916_A.T. Mussen.docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1916/1916_D. Orr.docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1916/1916_Eijkman, C. .docx',\n"," '/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/1916/1916_J. COLLIER.docx']"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# Uses lemmatization and stopwords \n","file_paths = all_papers_path\n","\n","proc_docs = [] \n","\n","counter = 1\n","length = len(file_paths)\n","for f in file_paths:\n","  doc = get_docx(f)\n","  \n","  for sentence in doc:\n","    proc_sentence = [] \n","    # changed to >=2 word length for molecules with smaller abbreviation \n","    proc_sentence = [word for word in re.findall(r'\\w+', sentence) if ((len(word) >= 2) and (word not in STOPWORDS))]\n","\n","    # proc_sentence = do_lemmatizing(proc_sentence) \n","    \n","    proc_docs.append(proc_sentence)  \n","\n","  print(\"\\t{}/{}\".format(counter, length))\n","  counter += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmQ27ZBecODh","executionInfo":{"status":"ok","timestamp":1675649135530,"user_tz":300,"elapsed":201445,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"outputId":"b9a3e538-fa9d-47dc-ab0a-388db1474e0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\t1/700\n","\t2/700\n","\t3/700\n","\t4/700\n","\t5/700\n","\t6/700\n","\t7/700\n","\t8/700\n","\t9/700\n","\t10/700\n","\t11/700\n","\t12/700\n","\t13/700\n","\t14/700\n","\t15/700\n","\t16/700\n","\t17/700\n","\t18/700\n","\t19/700\n","\t20/700\n","\t21/700\n","\t22/700\n","\t23/700\n","\t24/700\n","\t25/700\n","\t26/700\n","\t27/700\n","\t28/700\n","\t29/700\n","\t30/700\n","\t31/700\n","\t32/700\n","\t33/700\n","\t34/700\n","\t35/700\n","\t36/700\n","\t37/700\n","\t38/700\n","\t39/700\n","\t40/700\n","\t41/700\n","\t42/700\n","\t43/700\n","\t44/700\n","\t45/700\n","\t46/700\n","\t47/700\n","\t48/700\n","\t49/700\n","\t50/700\n","\t51/700\n","\t52/700\n","\t53/700\n","\t54/700\n","\t55/700\n","\t56/700\n","\t57/700\n","\t58/700\n","\t59/700\n","\t60/700\n","\t61/700\n","\t62/700\n","\t63/700\n","\t64/700\n","\t65/700\n","\t66/700\n","\t67/700\n","\t68/700\n","\t69/700\n","\t70/700\n","\t71/700\n","\t72/700\n","\t73/700\n","\t74/700\n","\t75/700\n","\t76/700\n","\t77/700\n","\t78/700\n","\t79/700\n","\t80/700\n","\t81/700\n","\t82/700\n","\t83/700\n","\t84/700\n","\t85/700\n","\t86/700\n","\t87/700\n","\t88/700\n","\t89/700\n","\t90/700\n","\t91/700\n","\t92/700\n","\t93/700\n","\t94/700\n","\t95/700\n","\t96/700\n","\t97/700\n","\t98/700\n","\t99/700\n","\t100/700\n","\t101/700\n","\t102/700\n","\t103/700\n","\t104/700\n","\t105/700\n","\t106/700\n","\t107/700\n","\t108/700\n","\t109/700\n","\t110/700\n","\t111/700\n","\t112/700\n","\t113/700\n","\t114/700\n","\t115/700\n","\t116/700\n","\t117/700\n","\t118/700\n","\t119/700\n","\t120/700\n","\t121/700\n","\t122/700\n","\t123/700\n","\t124/700\n","\t125/700\n","\t126/700\n","\t127/700\n","\t128/700\n","\t129/700\n","\t130/700\n","\t131/700\n","\t132/700\n","\t133/700\n","\t134/700\n","\t135/700\n","\t136/700\n","\t137/700\n","\t138/700\n","\t139/700\n","\t140/700\n","\t141/700\n","\t142/700\n","\t143/700\n","\t144/700\n","\t145/700\n","\t146/700\n","\t147/700\n","\t148/700\n","\t149/700\n","\t150/700\n","\t151/700\n","\t152/700\n","\t153/700\n","\t154/700\n","\t155/700\n","\t156/700\n","\t157/700\n","\t158/700\n","\t159/700\n","\t160/700\n","\t161/700\n","\t162/700\n","\t163/700\n","\t164/700\n","\t165/700\n","\t166/700\n","\t167/700\n","\t168/700\n","\t169/700\n","\t170/700\n","\t171/700\n","\t172/700\n","\t173/700\n","\t174/700\n","\t175/700\n","\t176/700\n","\t177/700\n","\t178/700\n","\t179/700\n","\t180/700\n","\t181/700\n","\t182/700\n","\t183/700\n","\t184/700\n","\t185/700\n","\t186/700\n","\t187/700\n","\t188/700\n","\t189/700\n","\t190/700\n","\t191/700\n","\t192/700\n","\t193/700\n","\t194/700\n","\t195/700\n","\t196/700\n","\t197/700\n","\t198/700\n","\t199/700\n","\t200/700\n","\t201/700\n","\t202/700\n","\t203/700\n","\t204/700\n","\t205/700\n","\t206/700\n","\t207/700\n","\t208/700\n","\t209/700\n","\t210/700\n","\t211/700\n","\t212/700\n","\t213/700\n","\t214/700\n","\t215/700\n","\t216/700\n","\t217/700\n","\t218/700\n","\t219/700\n","\t220/700\n","\t221/700\n","\t222/700\n","\t223/700\n","\t224/700\n","\t225/700\n","\t226/700\n","\t227/700\n","\t228/700\n","\t229/700\n","\t230/700\n","\t231/700\n","\t232/700\n","\t233/700\n","\t234/700\n","\t235/700\n","\t236/700\n","\t237/700\n","\t238/700\n","\t239/700\n","\t240/700\n","\t241/700\n","\t242/700\n","\t243/700\n","\t244/700\n","\t245/700\n","\t246/700\n","\t247/700\n","\t248/700\n","\t249/700\n","\t250/700\n","\t251/700\n","\t252/700\n","\t253/700\n","\t254/700\n","\t255/700\n","\t256/700\n","\t257/700\n","\t258/700\n","\t259/700\n","\t260/700\n","\t261/700\n","\t262/700\n","\t263/700\n","\t264/700\n","\t265/700\n","\t266/700\n","\t267/700\n","\t268/700\n","\t269/700\n","\t270/700\n","\t271/700\n","\t272/700\n","\t273/700\n","\t274/700\n","\t275/700\n","\t276/700\n","\t277/700\n","\t278/700\n","\t279/700\n","\t280/700\n","\t281/700\n","\t282/700\n","\t283/700\n","\t284/700\n","\t285/700\n","\t286/700\n","\t287/700\n","\t288/700\n","\t289/700\n","\t290/700\n","\t291/700\n","\t292/700\n","\t293/700\n","\t294/700\n","\t295/700\n","\t296/700\n","\t297/700\n","\t298/700\n","\t299/700\n","\t300/700\n","\t301/700\n","\t302/700\n","\t303/700\n","\t304/700\n","\t305/700\n","\t306/700\n","\t307/700\n","\t308/700\n","\t309/700\n","\t310/700\n","\t311/700\n","\t312/700\n","\t313/700\n","\t314/700\n","\t315/700\n","\t316/700\n","\t317/700\n","\t318/700\n","\t319/700\n","\t320/700\n","\t321/700\n","\t322/700\n","\t323/700\n","\t324/700\n","\t325/700\n","\t326/700\n","\t327/700\n","\t328/700\n","\t329/700\n","\t330/700\n","\t331/700\n","\t332/700\n","\t333/700\n","\t334/700\n","\t335/700\n","\t336/700\n","\t337/700\n","\t338/700\n","\t339/700\n","\t340/700\n","\t341/700\n","\t342/700\n","\t343/700\n","\t344/700\n","\t345/700\n","\t346/700\n","\t347/700\n","\t348/700\n","\t349/700\n","\t350/700\n","\t351/700\n","\t352/700\n","\t353/700\n","\t354/700\n","\t355/700\n","\t356/700\n","\t357/700\n","\t358/700\n","\t359/700\n","\t360/700\n","\t361/700\n","\t362/700\n","\t363/700\n","\t364/700\n","\t365/700\n","\t366/700\n","\t367/700\n","\t368/700\n","\t369/700\n","\t370/700\n","\t371/700\n","\t372/700\n","\t373/700\n","\t374/700\n","\t375/700\n","\t376/700\n","\t377/700\n","\t378/700\n","\t379/700\n","\t380/700\n","\t381/700\n","\t382/700\n","\t383/700\n","\t384/700\n","\t385/700\n","\t386/700\n","\t387/700\n","\t388/700\n","\t389/700\n","\t390/700\n","\t391/700\n","\t392/700\n","\t393/700\n","\t394/700\n","\t395/700\n","\t396/700\n","\t397/700\n","\t398/700\n","\t399/700\n","\t400/700\n","\t401/700\n","\t402/700\n","\t403/700\n","\t404/700\n","\t405/700\n","\t406/700\n","\t407/700\n","\t408/700\n","\t409/700\n","\t410/700\n","\t411/700\n","\t412/700\n","\t413/700\n","\t414/700\n","\t415/700\n","\t416/700\n","\t417/700\n","\t418/700\n","\t419/700\n","\t420/700\n","\t421/700\n","\t422/700\n","\t423/700\n","\t424/700\n","\t425/700\n","\t426/700\n","\t427/700\n","\t428/700\n","\t429/700\n","\t430/700\n","\t431/700\n","\t432/700\n","\t433/700\n","\t434/700\n","\t435/700\n","\t436/700\n","\t437/700\n","\t438/700\n","\t439/700\n","\t440/700\n","\t441/700\n","\t442/700\n","\t443/700\n","\t444/700\n","\t445/700\n","\t446/700\n","\t447/700\n","\t448/700\n","\t449/700\n","\t450/700\n","\t451/700\n","\t452/700\n","\t453/700\n","\t454/700\n","\t455/700\n","\t456/700\n","\t457/700\n","\t458/700\n","\t459/700\n","\t460/700\n","\t461/700\n","\t462/700\n","\t463/700\n","\t464/700\n","\t465/700\n","\t466/700\n","\t467/700\n","\t468/700\n","\t469/700\n","\t470/700\n","\t471/700\n","\t472/700\n","\t473/700\n","\t474/700\n","\t475/700\n","\t476/700\n","\t477/700\n","\t478/700\n","\t479/700\n","\t480/700\n","\t481/700\n","\t482/700\n","\t483/700\n","\t484/700\n","\t485/700\n","\t486/700\n","\t487/700\n","\t488/700\n","\t489/700\n","\t490/700\n","\t491/700\n","\t492/700\n","\t493/700\n","\t494/700\n","\t495/700\n","\t496/700\n","\t497/700\n","\t498/700\n","\t499/700\n","\t500/700\n","\t501/700\n","\t502/700\n","\t503/700\n","\t504/700\n","\t505/700\n","\t506/700\n","\t507/700\n","\t508/700\n","\t509/700\n","\t510/700\n","\t511/700\n","\t512/700\n","\t513/700\n","\t514/700\n","\t515/700\n","\t516/700\n","\t517/700\n","\t518/700\n","\t519/700\n","\t520/700\n","\t521/700\n","\t522/700\n","\t523/700\n","\t524/700\n","\t525/700\n","\t526/700\n","\t527/700\n","\t528/700\n","\t529/700\n","\t530/700\n","\t531/700\n","\t532/700\n","\t533/700\n","\t534/700\n","\t535/700\n","\t536/700\n","\t537/700\n","\t538/700\n","\t539/700\n","\t540/700\n","\t541/700\n","\t542/700\n","\t543/700\n","\t544/700\n","\t545/700\n","\t546/700\n","\t547/700\n","\t548/700\n","\t549/700\n","\t550/700\n","\t551/700\n","\t552/700\n","\t553/700\n","\t554/700\n","\t555/700\n","\t556/700\n","\t557/700\n","\t558/700\n","\t559/700\n","\t560/700\n","\t561/700\n","\t562/700\n","\t563/700\n","\t564/700\n","\t565/700\n","\t566/700\n","\t567/700\n","\t568/700\n","\t569/700\n","\t570/700\n","\t571/700\n","\t572/700\n","\t573/700\n","\t574/700\n","\t575/700\n","\t576/700\n","\t577/700\n","\t578/700\n","\t579/700\n","\t580/700\n","\t581/700\n","\t582/700\n","\t583/700\n","\t584/700\n","\t585/700\n","\t586/700\n","\t587/700\n","\t588/700\n","\t589/700\n","\t590/700\n","\t591/700\n","\t592/700\n","\t593/700\n","\t594/700\n","\t595/700\n","\t596/700\n","\t597/700\n","\t598/700\n","\t599/700\n","\t600/700\n","\t601/700\n","\t602/700\n","\t603/700\n","\t604/700\n","\t605/700\n","\t606/700\n","\t607/700\n","\t608/700\n","\t609/700\n","\t610/700\n","\t611/700\n","\t612/700\n","\t613/700\n","\t614/700\n","\t615/700\n","\t616/700\n","\t617/700\n","\t618/700\n","\t619/700\n","\t620/700\n","\t621/700\n","\t622/700\n","\t623/700\n","\t624/700\n","\t625/700\n","\t626/700\n","\t627/700\n","\t628/700\n","\t629/700\n","\t630/700\n","\t631/700\n","\t632/700\n","\t633/700\n","\t634/700\n","\t635/700\n","\t636/700\n","\t637/700\n","\t638/700\n","\t639/700\n","\t640/700\n","\t641/700\n","\t642/700\n","\t643/700\n","\t644/700\n","\t645/700\n","\t646/700\n","\t647/700\n","\t648/700\n","\t649/700\n","\t650/700\n","\t651/700\n","\t652/700\n","\t653/700\n","\t654/700\n","\t655/700\n","\t656/700\n","\t657/700\n","\t658/700\n","\t659/700\n","\t660/700\n","\t661/700\n","\t662/700\n","\t663/700\n","\t664/700\n","\t665/700\n","\t666/700\n","\t667/700\n","\t668/700\n","\t669/700\n","\t670/700\n","\t671/700\n","\t672/700\n","\t673/700\n","\t674/700\n","\t675/700\n","\t676/700\n","\t677/700\n","\t678/700\n","\t679/700\n","\t680/700\n","\t681/700\n","\t682/700\n","\t683/700\n","\t684/700\n","\t685/700\n","\t686/700\n","\t687/700\n","\t688/700\n","\t689/700\n","\t690/700\n","\t691/700\n","\t692/700\n","\t693/700\n","\t694/700\n","\t695/700\n","\t696/700\n","\t697/700\n","\t698/700\n","\t699/700\n","\t700/700\n"]}]},{"cell_type":"code","source":["# Train the embeddings!\n","from gensim.models.fasttext import FastText\n","print(\"Training fasttext word embeddings for all papers...\")\n","model = FastText(sentences=proc_docs, min_count = 1 )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cL4lEFpc3ZW","executionInfo":{"status":"ok","timestamp":1675650025274,"user_tz":300,"elapsed":168542,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"outputId":"34fb1bec-e556-422d-ec0e-afa33b18c22c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training fasttext word embeddings for all papers...\n"]}]},{"cell_type":"code","source":["# Sanity check \n","print(model.wv.most_similar(\"akt-3\", topn=10))\n","\n","# Store just the words + their trained embeddings.\n","word_vectors = model.wv\n","word_vectors.save(\"/content/drive/MyDrive/Colab Notebooks/NLP - Lab/WordEmbeddings/Models/Gensim_Lemmatized_All_Docs/FastText.wordvectors\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E4fn7HSGdSF9","executionInfo":{"status":"ok","timestamp":1675650187157,"user_tz":300,"elapsed":2858,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"outputId":"e6546871-25c0-45ea-95e4-2b603d95464a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('akt', 0.8763183951377869), ('akt1', 0.8671360015869141), ('rhoe', 0.8668363094329834), ('rhob', 0.8653501272201538), ('smad2', 0.8633884191513062), ('rho1', 0.8628695607185364), ('wjjak', 0.8625777363777161), ('rhomhanyi', 0.8620971441268921), ('rhogdi', 0.8587667942047119), ('smad1', 0.8587009310722351)]\n"]}]},{"cell_type":"markdown","source":["# Byte Pair Encoding using Hugging Face Tokenizers"],"metadata":{"id":"KemvsVw0zWDC"}},{"cell_type":"code","source":["all_papers_path = glob.glob('/content/drive/MyDrive/regen_x/data/ocr_paper_COMPREHENSIVE/*/*.docx')\n","all_papers_path[160:170]"],"metadata":{"id":"AcWuVATx75Jz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DON\"T lemmatize or use stopwords for Byte Pair Encoding  \n","def sentence_generator():\n","  file_paths = all_papers_path\n","  counter = 1\n","  length = len(file_paths)\n","  for f in file_paths:\n","    print(\"\\t{}/{}\".format(counter, length))\n","    doc = get_docx(f)\n","    yield doc # speed up by returning batch of sentences \n","\n","    counter += 1"],"metadata":{"id":"iiOFm4A5-24G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tokenizers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJ3M5zKe9u5E","executionInfo":{"status":"ok","timestamp":1675644514126,"user_tz":300,"elapsed":2297,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"outputId":"37f1ccd5-cd27-433c-9ce8-d7639cfc16ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.13.2\n"]}]},{"cell_type":"markdown","source":["Bert WordPiece-style Encoding"],"metadata":{"id":"PsNuZc4jKjaX"}},{"cell_type":"code","source":["from tokenizers import Tokenizer\n","from tokenizers.models import WordPiece\n","bert_tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))"],"metadata":{"id":"LHOAgGLGKgr4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tokenizers import normalizers\n","from tokenizers.normalizers import NFD, Lowercase, StripAccents\n","bert_tokenizer.normalizer = normalizers.Sequence([NFD(), Lowercase(), StripAccents()])"],"metadata":{"id":"6sb3jxgrKi9t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tokenizers.pre_tokenizers import Whitespace\n","bert_tokenizer.pre_tokenizer = Whitespace()"],"metadata":{"id":"tr0ozlU9KpGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tokenizers.trainers import WordPieceTrainer\n","trainer = WordPieceTrainer(vocab_size=30522, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])"],"metadata":{"id":"XfdDFrK3KyPW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Byte-Pair Encoding"],"metadata":{"id":"JYyug9ktKmJo"}},{"cell_type":"code","source":["# from tokenizers import Tokenizer\n","# from tokenizers.models import BPE\n","# tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))"],"metadata":{"id":"maerROVu0oXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from tokenizers.trainers import BpeTrainer\n","# trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])"],"metadata":{"id":"3HPoxjiF62gk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from tokenizers.pre_tokenizers import ByteLevel\n","# tokenizer.pre_tokenizer = ByteLevel()"],"metadata":{"id":"EtuMpJ9H93HY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from tokenizers import normalizers\n","# from tokenizers.normalizers import NFD, StripAccents\n","# normalizer = normalizers.Sequence([NFD(), StripAccents()])\n","# tokenizer.normalizer = normalizer"],"metadata":{"id":"FbVTaaQiJD6z"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"executionInfo":{"status":"ok","timestamp":1675647320125,"user_tz":300,"elapsed":2720507,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"id":"hyajQk5K75Jy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd3ea43a-4dff-4ffc-c83e-85e8ed1ae831"},"source":["bert_tokenizer.train_from_iterator(sentence_generator(), trainer)\n","bert_tokenizer.save(\"/content/drive/MyDrive/Colab Notebooks/NLP - Lab/WordEmbeddings/Models/BPE/WordPiece_Normalized_ByteLevel_30522_words.json\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\t1/700\n","\t2/700\n","\t3/700\n","\t4/700\n","\t5/700\n","\t6/700\n","\t7/700\n","\t8/700\n","\t9/700\n","\t10/700\n","\t11/700\n","\t12/700\n","\t13/700\n","\t14/700\n","\t15/700\n","\t16/700\n","\t17/700\n","\t18/700\n","\t19/700\n","\t20/700\n","\t21/700\n","\t22/700\n","\t23/700\n","\t24/700\n","\t25/700\n","\t26/700\n","\t27/700\n","\t28/700\n","\t29/700\n","\t30/700\n","\t31/700\n","\t32/700\n","\t33/700\n","\t34/700\n","\t35/700\n","\t36/700\n","\t37/700\n","\t38/700\n","\t39/700\n","\t40/700\n","\t41/700\n","\t42/700\n","\t43/700\n","\t44/700\n","\t45/700\n","\t46/700\n","\t47/700\n","\t48/700\n","\t49/700\n","\t50/700\n","\t51/700\n","\t52/700\n","\t53/700\n","\t54/700\n","\t55/700\n","\t56/700\n","\t57/700\n","\t58/700\n","\t59/700\n","\t60/700\n","\t61/700\n","\t62/700\n","\t63/700\n","\t64/700\n","\t65/700\n","\t66/700\n","\t67/700\n","\t68/700\n","\t69/700\n","\t70/700\n","\t71/700\n","\t72/700\n","\t73/700\n","\t74/700\n","\t75/700\n","\t76/700\n","\t77/700\n","\t78/700\n","\t79/700\n","\t80/700\n","\t81/700\n","\t82/700\n","\t83/700\n","\t84/700\n","\t85/700\n","\t86/700\n","\t87/700\n","\t88/700\n","\t89/700\n","\t90/700\n","\t91/700\n","\t92/700\n","\t93/700\n","\t94/700\n","\t95/700\n","\t96/700\n","\t97/700\n","\t98/700\n","\t99/700\n","\t100/700\n","\t101/700\n","\t102/700\n","\t103/700\n","\t104/700\n","\t105/700\n","\t106/700\n","\t107/700\n","\t108/700\n","\t109/700\n","\t110/700\n","\t111/700\n","\t112/700\n","\t113/700\n","\t114/700\n","\t115/700\n","\t116/700\n","\t117/700\n","\t118/700\n","\t119/700\n","\t120/700\n","\t121/700\n","\t122/700\n","\t123/700\n","\t124/700\n","\t125/700\n","\t126/700\n","\t127/700\n","\t128/700\n","\t129/700\n","\t130/700\n","\t131/700\n","\t132/700\n","\t133/700\n","\t134/700\n","\t135/700\n","\t136/700\n","\t137/700\n","\t138/700\n","\t139/700\n","\t140/700\n","\t141/700\n","\t142/700\n","\t143/700\n","\t144/700\n","\t145/700\n","\t146/700\n","\t147/700\n","\t148/700\n","\t149/700\n","\t150/700\n","\t151/700\n","\t152/700\n","\t153/700\n","\t154/700\n","\t155/700\n","\t156/700\n","\t157/700\n","\t158/700\n","\t159/700\n","\t160/700\n","\t161/700\n","\t162/700\n","\t163/700\n","\t164/700\n","\t165/700\n","\t166/700\n","\t167/700\n","\t168/700\n","\t169/700\n","\t170/700\n","\t171/700\n","\t172/700\n","\t173/700\n","\t174/700\n","\t175/700\n","\t176/700\n","\t177/700\n","\t178/700\n","\t179/700\n","\t180/700\n","\t181/700\n","\t182/700\n","\t183/700\n","\t184/700\n","\t185/700\n","\t186/700\n","\t187/700\n","\t188/700\n","\t189/700\n","\t190/700\n","\t191/700\n","\t192/700\n","\t193/700\n","\t194/700\n","\t195/700\n","\t196/700\n","\t197/700\n","\t198/700\n","\t199/700\n","\t200/700\n","\t201/700\n","\t202/700\n","\t203/700\n","\t204/700\n","\t205/700\n","\t206/700\n","\t207/700\n","\t208/700\n","\t209/700\n","\t210/700\n","\t211/700\n","\t212/700\n","\t213/700\n","\t214/700\n","\t215/700\n","\t216/700\n","\t217/700\n","\t218/700\n","\t219/700\n","\t220/700\n","\t221/700\n","\t222/700\n","\t223/700\n","\t224/700\n","\t225/700\n","\t226/700\n","\t227/700\n","\t228/700\n","\t229/700\n","\t230/700\n","\t231/700\n","\t232/700\n","\t233/700\n","\t234/700\n","\t235/700\n","\t236/700\n","\t237/700\n","\t238/700\n","\t239/700\n","\t240/700\n","\t241/700\n","\t242/700\n","\t243/700\n","\t244/700\n","\t245/700\n","\t246/700\n","\t247/700\n","\t248/700\n","\t249/700\n","\t250/700\n","\t251/700\n","\t252/700\n","\t253/700\n","\t254/700\n","\t255/700\n","\t256/700\n","\t257/700\n","\t258/700\n","\t259/700\n","\t260/700\n","\t261/700\n","\t262/700\n","\t263/700\n","\t264/700\n","\t265/700\n","\t266/700\n","\t267/700\n","\t268/700\n","\t269/700\n","\t270/700\n","\t271/700\n","\t272/700\n","\t273/700\n","\t274/700\n","\t275/700\n","\t276/700\n","\t277/700\n","\t278/700\n","\t279/700\n","\t280/700\n","\t281/700\n","\t282/700\n","\t283/700\n","\t284/700\n","\t285/700\n","\t286/700\n","\t287/700\n","\t288/700\n","\t289/700\n","\t290/700\n","\t291/700\n","\t292/700\n","\t293/700\n","\t294/700\n","\t295/700\n","\t296/700\n","\t297/700\n","\t298/700\n","\t299/700\n","\t300/700\n","\t301/700\n","\t302/700\n","\t303/700\n","\t304/700\n","\t305/700\n","\t306/700\n","\t307/700\n","\t308/700\n","\t309/700\n","\t310/700\n","\t311/700\n","\t312/700\n","\t313/700\n","\t314/700\n","\t315/700\n","\t316/700\n","\t317/700\n","\t318/700\n","\t319/700\n","\t320/700\n","\t321/700\n","\t322/700\n","\t323/700\n","\t324/700\n","\t325/700\n","\t326/700\n","\t327/700\n","\t328/700\n","\t329/700\n","\t330/700\n","\t331/700\n","\t332/700\n","\t333/700\n","\t334/700\n","\t335/700\n","\t336/700\n","\t337/700\n","\t338/700\n","\t339/700\n","\t340/700\n","\t341/700\n","\t342/700\n","\t343/700\n","\t344/700\n","\t345/700\n","\t346/700\n","\t347/700\n","\t348/700\n","\t349/700\n","\t350/700\n","\t351/700\n","\t352/700\n","\t353/700\n","\t354/700\n","\t355/700\n","\t356/700\n","\t357/700\n","\t358/700\n","\t359/700\n","\t360/700\n","\t361/700\n","\t362/700\n","\t363/700\n","\t364/700\n","\t365/700\n","\t366/700\n","\t367/700\n","\t368/700\n","\t369/700\n","\t370/700\n","\t371/700\n","\t372/700\n","\t373/700\n","\t374/700\n","\t375/700\n","\t376/700\n","\t377/700\n","\t378/700\n","\t379/700\n","\t380/700\n","\t381/700\n","\t382/700\n","\t383/700\n","\t384/700\n","\t386/700\n","\t387/700\n","\t388/700\n","\t389/700\n","\t390/700\n","\t391/700\n","\t392/700\n","\t393/700\n","\t394/700\n","\t395/700\n","\t396/700\n","\t397/700\n","\t398/700\n","\t399/700\n","\t400/700\n","\t401/700\n","\t402/700\n","\t403/700\n","\t404/700\n","\t405/700\n","\t406/700\n","\t407/700\n","\t408/700\n","\t409/700\n","\t410/700\n","\t411/700\n","\t412/700\n","\t413/700\n","\t414/700\n","\t415/700\n","\t416/700\n","\t417/700\n","\t418/700\n","\t419/700\n","\t420/700\n","\t421/700\n","\t422/700\n","\t423/700\n","\t424/700\n","\t425/700\n","\t426/700\n","\t427/700\n","\t428/700\n","\t429/700\n","\t430/700\n","\t431/700\n","\t432/700\n","\t433/700\n","\t434/700\n","\t435/700\n","\t436/700\n","\t437/700\n","\t438/700\n","\t439/700\n","\t440/700\n","\t441/700\n","\t442/700\n","\t443/700\n","\t444/700\n","\t445/700\n","\t446/700\n","\t447/700\n","\t448/700\n","\t449/700\n","\t450/700\n","\t451/700\n","\t452/700\n","\t453/700\n","\t454/700\n","\t455/700\n","\t456/700\n","\t457/700\n","\t458/700\n","\t459/700\n","\t460/700\n","\t461/700\n","\t462/700\n","\t463/700\n","\t464/700\n","\t465/700\n","\t466/700\n","\t467/700\n","\t468/700\n","\t469/700\n","\t470/700\n","\t471/700\n","\t472/700\n","\t473/700\n","\t474/700\n","\t475/700\n","\t476/700\n","\t477/700\n","\t478/700\n","\t479/700\n","\t480/700\n","\t481/700\n","\t482/700\n","\t483/700\n","\t484/700\n","\t485/700\n","\t486/700\n","\t487/700\n","\t488/700\n","\t489/700\n","\t490/700\n","\t491/700\n","\t492/700\n","\t493/700\n","\t494/700\n","\t495/700\n","\t496/700\n","\t497/700\n","\t498/700\n","\t499/700\n","\t500/700\n","\t501/700\n","\t502/700\n","\t503/700\n","\t504/700\n","\t505/700\n","\t506/700\n","\t507/700\n","\t508/700\n","\t509/700\n","\t510/700\n","\t511/700\n","\t512/700\n","\t513/700\n","\t514/700\n","\t515/700\n","\t516/700\n","\t517/700\n","\t518/700\n","\t519/700\n","\t520/700\n","\t521/700\n","\t522/700\n","\t523/700\n","\t524/700\n","\t525/700\n","\t526/700\n","\t527/700\n","\t528/700\n","\t529/700\n","\t530/700\n","\t531/700\n","\t532/700\n","\t533/700\n","\t534/700\n","\t535/700\n","\t536/700\n","\t537/700\n","\t538/700\n","\t539/700\n","\t540/700\n","\t541/700\n","\t542/700\n","\t543/700\n","\t544/700\n","\t545/700\n","\t546/700\n","\t547/700\n","\t548/700\n","\t549/700\n","\t550/700\n","\t551/700\n","\t552/700\n","\t553/700\n","\t554/700\n","\t555/700\n","\t556/700\n","\t557/700\n","\t558/700\n","\t559/700\n","\t560/700\n","\t561/700\n","\t562/700\n","\t563/700\n","\t564/700\n","\t565/700\n","\t566/700\n","\t567/700\n","\t568/700\n","\t569/700\n","\t570/700\n","\t571/700\n","\t572/700\n","\t573/700\n","\t574/700\n","\t575/700\n","\t576/700\n","\t577/700\n","\t578/700\n","\t579/700\n","\t580/700\n","\t581/700\n","\t582/700\n","\t583/700\n","\t584/700\n","\t585/700\n","\t586/700\n","\t587/700\n","\t588/700\n","\t589/700\n","\t590/700\n","\t591/700\n","\t592/700\n","\t593/700\n","\t594/700\n","\t595/700\n","\t596/700\n","\t597/700\n","\t598/700\n","\t599/700\n","\t600/700\n","\t601/700\n","\t602/700\n","\t603/700\n","\t604/700\n","\t605/700\n","\t606/700\n","\t607/700\n","\t608/700\n","\t609/700\n","\t610/700\n","\t611/700\n","\t612/700\n","\t613/700\n","\t614/700\n","\t615/700\n","\t616/700\n","\t617/700\n","\t618/700\n","\t619/700\n","\t620/700\n","\t621/700\n","\t622/700\n","\t623/700\n","\t624/700\n","\t625/700\n","\t626/700\n","\t627/700\n","\t628/700\n","\t629/700\n","\t630/700\n","\t631/700\n","\t632/700\n","\t633/700\n","\t634/700\n","\t635/700\n","\t636/700\n","\t637/700\n","\t638/700\n","\t639/700\n","\t640/700\n","\t641/700\n","\t642/700\n","\t643/700\n","\t644/700\n","\t645/700\n","\t646/700\n","\t647/700\n","\t648/700\n","\t649/700\n","\t650/700\n","\t651/700\n","\t652/700\n","\t653/700\n","\t654/700\n","\t655/700\n","\t656/700\n","\t657/700\n","\t658/700\n","\t659/700\n","\t660/700\n","\t661/700\n","\t662/700\n","\t663/700\n","\t664/700\n","\t665/700\n","\t666/700\n","\t667/700\n","\t668/700\n","\t669/700\n","\t670/700\n","\t671/700\n","\t672/700\n","\t673/700\n","\t674/700\n","\t675/700\n","\t676/700\n","\t677/700\n","\t678/700\n","\t679/700\n","\t680/700\n","\t681/700\n","\t682/700\n","\t683/700\n","\t684/700\n","\t685/700\n","\t686/700\n","\t687/700\n","\t688/700\n","\t689/700\n","\t690/700\n","\t691/700\n","\t692/700\n","\t693/700\n","\t694/700\n","\t695/700\n","\t696/700\n","\t697/700\n","\t698/700\n","\t699/700\n","\t700/700\n"]}]},{"cell_type":"code","source":["# Hard to say because its supposed to be encoding at byte level but maybe still splits by whitespace? \n","output = bert_tokenizer.encode(\"Optic nerve regeneration is increased with akt-3. This is interesting\")\n","print(output.ids)\n","bert_tokenizer.decode(output.ids)\n","print(output.tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9owLOOPXlGZ","executionInfo":{"status":"ok","timestamp":1675647786380,"user_tz":300,"elapsed":388,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"outputId":"d2e62e80-8d4d-4322-acae-8a1144dfbc11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[693, 458, 668, 374, 1492, 395, 10197, 17, 23, 18, 475, 374, 2851]\n","['Ġoptic', 'Ġnerve', 'Ġregeneration', 'Ġis', 'Ġincreased', 'Ġwith', 'Ġakt', '-', '3', '.', 'Ġthis', 'Ġis', 'Ġinteresting']\n"]}]},{"cell_type":"code","source":["# Hard to say because its supposed to be encoding at byte level but maybe still splits by whitespace? \n","output = bert_tokenizer.encode(\"o\")\n","print(output.ids)\n","bert_tokenizer.decode(output.ids)\n","print(output.tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gT1BscBsabaO","executionInfo":{"status":"ok","timestamp":1675648235093,"user_tz":300,"elapsed":1027,"user":{"displayName":"Varun Krishnan","userId":"10781844920353862932"}},"outputId":"5e66fdd4-1e11-44e7-9323-bd992b91e5dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[312, 318]\n","['Ġo', 'Ġp']\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"ytVwkCsGZ2bC"}}]}